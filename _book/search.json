[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wizualizacja Danych 2024",
    "section": "",
    "text": "1 Wizualizacja Danych 2024\nMateriały na semestr letni - rok akademicki 2023/24.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Wizualizacja Danych 2024</span>"
    ]
  },
  {
    "objectID": "trocheteorii.html",
    "href": "trocheteorii.html",
    "title": "2  Trochę teorii…",
    "section": "",
    "text": "2.1 Test racjonalnego myślenia\nWizualizacja – ogólna nazwa graficznych metod tworzenia, analizy i przekazywania informacji. Za pomocą środków wizualnych ludzie wymieniają się zarówno ideami abstrakcyjnymi, jak i komunikatami mającymi bezpośrednie oparcie w rzeczywistości. W dzisiejszych czasach wizualizacja wpływa na sposób prowadzenia badań naukowych, jest rutynowo wykorzystywana w dyscyplinach technicznych i medycynie, służy celom dydaktycznym, a także bywa pojmowana jako środek wyrazu artystycznego.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Trochę teorii...</span>"
    ]
  },
  {
    "objectID": "trocheteorii.html#test-racjonalnego-myślenia",
    "href": "trocheteorii.html#test-racjonalnego-myślenia",
    "title": "2  Trochę teorii…",
    "section": "",
    "text": "Jeśli 5 maszyn w ciągu 5 minut produkuje 5 urządzeń, ile czasu zajmie 100 maszynom zrobienie 100 urządzeń?\nNa stawie rozrasta się kępa lilii wodnych. Codziennie kępa staje się dwukrotnie większa. Jeśli zarośnięcie całego stawu zajmie liliom 48 dni, to ile dni potrzeba, żeby zarosły połowę stawu?\nKij bejsbolowy i piłka kosztują razem 1 dolar i 10 centów. Kij kosztuje o dolara więcej niż piłka. Ile kosztuje piłka?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Trochę teorii...</span>"
    ]
  },
  {
    "objectID": "trocheteorii.html#analiza-danych---podstawowe-pojęcia",
    "href": "trocheteorii.html#analiza-danych---podstawowe-pojęcia",
    "title": "2  Trochę teorii…",
    "section": "2.2 Analiza danych - podstawowe pojęcia",
    "text": "2.2 Analiza danych - podstawowe pojęcia\n\n2.2.1 Współczesne znaczenia słowa “statystyka”:\n\nzbiór danych liczbowych pokazujący kształtowanie procesów i zjawisk np. statystyka ludności.\nwszelkie czynności związane z gromadzeniem i opracowywaniem danych liczbowych np. statystyka pewnego problemu dokonywana przez GUS.\ncharakterystyki liczbowe np. statystyki próby np. średnia arytmetyczna, odchylenie standardowe itp.\ndyscyplina naukowa - nauka o metodach badania zjawisk masowych.\n\n\n\n2.2.2 “Masowość”\nZjawiska/procesy masowe - badaniu podlega duża liczba jednostek. Dzielą się na:\n\ngospodarcze (np. produkcja, konsumpcja, usługi reklama),\nspołeczne (np. wypadki drogowe, poglądy polityczne),\ndemograficzne (np. urodzenia, starzenie, migracje).\n\n\n\n2.2.3 Podział statystyki\nStatystyka - dyscyplina naukowa - podział:\n\nstatystyka opisowa - zajmuje się sprawami związanymi z gromadzeniem, prezentacją, analizą i interpretacją danych liczbowych. Obserwacja obejmuje całą badaną zbiorowość.\nstatystyka matematyczna - uogólnienie wyników badania części zbiorowości (próby) na całą zbiorowość.\n\n\n\n2.2.4 Zbiorowość/populacja\nZbiorowość statystyczna, populacja statystyczna: zbiór obiektów podlegających badaniu statystycznemu. Tworzą je jednostki podobne do siebie, logicznie powiązane, lecz nie identyczne. Mają pewne cechy wspólne oraz pewne właściwości pozwalające je różnicować.\n\nprzykłady:\n\nbadanie wzrostu Polaków - mieszkańcy Polski\npoziom nauczania w szkołach woj. warmińsko-mazurskiego - szkoły woj. warmińsko-mazurskiego.\n\npodział:\n\nzbiorowość/populacja generalna - obejmuje całość,\nzbiorowość/populacja próbna (próba) - obejmuje część populacji.\n\n\n\n\n2.2.5 Jednostka statyczna\nJednostka statystyczna: każdy z elementów zbiorowości statystycznej.\n\nprzykłady:\n\nstudenci UWM - student UWM\nmieszkańcy Polski - każda osoba mieszkająca w Polsce\nmaszyny produkowane w fabryce - każda maszyna\n\n\n\n\n2.2.6 Cechy statystyczne\nCechy statystyczne\n\nwłaściwości charakteryzujące jednostki statystyczne w danej zbiorowości statystycznej.\ndzielimy je na stałe i zmienne.\n\nCechy stałe\n\ntakie właściwości, które są wspólne wszystkim jednostkom danej zbiorowości statystycznej.\npodział:\n\nrzeczowe - kto lub co jest przedmiotem badania statystycznego,\nczasowe - kiedy zostało przeprowadzone badanie lub jakiego okresu czasu dotyczy badanie,\nprzestrzenne - jakiego terytorium (miejsce lub obszar) dotyczy badanie.\n\nprzykład: studenci WMiI UWM w Olsztynie w roku akad. 2017/2018:\n\ncecha rzeczowa: posiadanie legitymacji studenckiej,\ncecha czasowa - studenci studiujący w roku akad. 2017/2018\ncecha przestrzenna - miejsce: WMiI UWM w Olsztynie.\n\n\nCechy zmienne\n\nwłaściwości różnicujące jednostki statystyczne w danej zbiorowości.\nprzykład: studenci UWM - cechy zmienne: wiek, płeć, rodzaj ukończonej szkoły średniej, kolor oczu, wzrost.\n\nWażne:\n\nobserwacji podlegają tylko cechy zmienne,\ncecha stała w jednej zbiorowości może być cechą zmienną w innej zbiorowości.\n\nPrzykład: studenci UWM mają legitymację wydaną przez UWM. Studenci wszystkich uczelni w Polsce mają legitymacje wydane przez różne szkoły.\nPodział cech zmiennych:\n\ncechy mierzalne (ilościowe) - można je wyrazić liczbą wraz z określoną jednostką miary.\ncechy niemierzalne (jakościowe) - określane słownie, reprezentują pewne kategorie.\n\nPrzykład: zbiorowość studentów. Cechy mierzalne: wiek, waga, wzrost, liczba nieobecności. Cechy niemierzalne: płeć, kolor oczu, kierunek studiów.\nCzęsto ze względów praktycznych cechom niemierzalnym przypisywane są kody liczbowe. Nie należy ich jednak mylić z cechami mierzalnymi. Np. 1 - wykształcenie podstawowe, 2 - wykształcenie zasadnicze, itd…\nPodział cech mierzalnych:\n\nciągłe - mogące przybrać każdą wartość z określonego przedziału, np. wzrost, wiek, powierzchnia mieszkania.\nskokowe - mogące przyjmować konkretne (dyskretne) wartości liczbowe bez wartości pośrednich np. liczba osób w gospodarstwie domowych, liczba osób zatrudnionych w danej firmie.\n\nCechy skokowe zazwyczaj mają wartości całkowite choć nie zawsze jest to wymagane np. liczba etatów w firmie (z uwzględnieniem części etatów).\n\n\n2.2.7 Skale\nSkala pomiarowa\n\nto system, pozwalający w pewien sposób usystematyzować wyniki pomiarów statystycznych.\npodział:\n\nskala nominalna,\nskala porządkowa,\nskala przedziałowa (interwałowa),\nskala ilorazowa (stosunkowa).\n\n\nSkala nominalna\n\nskala, w której klasyfikujemy jednostkę statystyczną do określonej kategorii.\nwartość w tej skali nie ma żadnego uporządkowana.\nprzykład:\n\n\n\n\nReligia\nKod\n\n\n\n\nChrześcijaństwo\n1\n\n\nIslam\n2\n\n\nBuddyzm\n3\n\n\n\nSkala porządkowa\n\nwartości mają jasno określony porządek, ale nie są dane odległości między nimi,\npozwala na uszeregowanie elementów.\nprzykłady:\n\n\n\n\nWykształcenie\nKod\n\n\n\n\nPodstawowe\n1\n\n\nŚrednie\n2\n\n\nWyższe\n3\n\n\n\n\n\n\nDochód\nKod\n\n\n\n\nNiski\n1\n\n\nŚredni\n2\n\n\nWysoki\n3\n\n\n\nSkala przedziałowa (interwałowa)\n\nwartości cechy wyrażone są poprzez konkretne wartości liczbowe,\npozwala na porównywanie jednostek (coś jest większe lub mniejsze),\nnie możliwe jest badanie ilorazów (określenie ile razy dana wartość jest większa lub mniejsza od drugiej).\nprzykład:\n\n\n\n\nMiasto\nTemperatura w \\(^{\\circ}C\\)\nTemperatura w \\(^{\\circ}F\\)\n\n\n\n\nWarszawa\n15\n59\n\n\nOlsztyn\n10\n50\n\n\nGdańsk\n5\n41\n\n\nSzczecin\n20\n68\n\n\n\nSkala ilorazowa (stosunkowa)\n\nwartości wyrażone są przez wartości liczbowe,\nmożliwe określenie jest relacji mniejsza lub większa między wartościami,\nmożliwe jest określenie stosunku (ilorazu) między wartościami,\nwystępuje zero absolutne.\nprzykład:\n\n\n\n\nProdukt\nCena w zł\n\n\n\n\nChleb\n3\n\n\nMasło\n8\n\n\nGruszki\n5",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Trochę teorii...</span>"
    ]
  },
  {
    "objectID": "trocheteorii.html#rodzaje-badań-statystycznych",
    "href": "trocheteorii.html#rodzaje-badań-statystycznych",
    "title": "2  Trochę teorii…",
    "section": "2.3 Rodzaje badań statystycznych",
    "text": "2.3 Rodzaje badań statystycznych\n\nbadanie pełne - obejmują wszystkie jednostki zbiorowości statystycznej.\n\nspis statystyczny,\nrejestracja bieżąca,\nsprawozdawczość statystyczna.\n\nbadania częściowe - obserwowana jest część populacji. Przeprowadza się wtedy gdy badanie pełne jest niecelowe lub niemożliwe.\n\nmetoda monograficzna,\nmetoda reprezentacyjna.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Trochę teorii...</span>"
    ]
  },
  {
    "objectID": "trocheteorii.html#etapy-badania-statystycznego",
    "href": "trocheteorii.html#etapy-badania-statystycznego",
    "title": "2  Trochę teorii…",
    "section": "2.4 Etapy badania statystycznego",
    "text": "2.4 Etapy badania statystycznego\n\nprojektowanie i organizacja badania: ustalenie celu, podmiotu, przedmiotu, zakresu, źródła i czasu trwania badania;\nobserwacja statystyczna;\nopracowanie materiału statystycznego: kontrola materiału statystycznego, grupowanie uzyskanych danych, prezentacja wyników danych;\nanaliza statystyczna.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Trochę teorii...</span>"
    ]
  },
  {
    "objectID": "trocheteorii.html#analiza-danych-zastanych",
    "href": "trocheteorii.html#analiza-danych-zastanych",
    "title": "2  Trochę teorii…",
    "section": "2.5 Analiza danych zastanych",
    "text": "2.5 Analiza danych zastanych\nAnaliza danych zastanych – proces przetwarzania danych w celu uzyskania na ich podstawie użytecznych informacji i wniosków. W zależności od rodzaju danych i stawianych problemów, może to oznaczać użycie metod statystycznych, eksploracyjnych i innych.\nKorzystanie z danych zastanych jest przykładem badań niereaktywnych - metod badań zachowań społecznych, które nie wpływają na te zachowania. Dane takie to: dokumenty, archiwa, sprawozdania, kroniki, spisy ludności, księgi parafialne, dzienniki, pamiętniki, blogi internetowe, audio-pamiętniki, archiwa historii mówionej i inne. (Wikipedia)\nDane zastane możemy podzielić ze względu na (Makowska red. 2013):\n\nCharakter: Ilościowe, Jakościowe\nFormę: Dane opracowane, Dane surowe\nSposób powstania: Pierwotne, Wtórne\nDynamikę: Ciągła rejestracja zdarzeń, Rejestracja w interwałach czasowych, Rejestracja jednorazowa\nPoziom obiektywizmu: Obiektywne, Subiektywne\nŹródła pochodzenia: Dane publiczne, Dane prywatne\n\nAnaliza danych to proces polegający na sprawdzaniu, porządkowaniu, przekształcaniu i modelowaniu danych w celu zdobycia użytecznych informacji, wypracowania wniosków i wspierania procesu decyzyjnego. Analiza danych ma wiele aspektów i podejść, obejmujących różne techniki pod różnymi nazwami, w różnych obszarach biznesowych, naukowych i społecznych. Praktyczne podejście do definiowania danych polega na tym, że dane to liczby, znaki, obrazy lub inne metody zapisu, w formie, którą można ocenić w celu określenia lub podjęcia decyzji o konkretnym działaniu. Wiele osób uważa, że dane same w sobie nie mają znaczenia – dopiero dane przetworzone i zinterpretowane stają się informacją.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Trochę teorii...</span>"
    ]
  },
  {
    "objectID": "trocheteorii.html#proces-analizy-danych",
    "href": "trocheteorii.html#proces-analizy-danych",
    "title": "2  Trochę teorii…",
    "section": "2.6 Proces analizy danych",
    "text": "2.6 Proces analizy danych\nAnaliza odnosi się do rozbicia całości posiadanych informacji na jej odrębne komponenty w celu indywidualnego badania. Analiza danych to proces uzyskiwania nieprzetworzonych danych i przekształcania ich w informacje przydatne do podejmowania decyzji przez użytkowników. Dane są zbierane i analizowane, aby odpowiadać na pytania, testować hipotezy lub obalać teorie. Istnieje kilka faz, które można wyszczególnić w procesie analizy danych. Fazy są iteracyjne, ponieważ informacje zwrotne z faz kolejnych mogą spowodować dodatkową pracę w fazach wcześniejszych.\n\n2.6.1 Zdefiniowanie wymagań\nPrzed przystąpieniem do analizy danych, należy dokładnie określić wymagania jakościowe dotyczące danych. Dane wejściowe, które mają być przedmiotem analizy, są określone na podstawie wymagań osób kierujących analizą lub klientów (którzy będą używać finalnego produktu analizy). Ogólny typ jednostki, na podstawie której dane będą zbierane, jest określany jako jednostka eksperymentalna (np. osoba lub populacja ludzi. Dane mogą być liczbowe lub kategoryczne (tj. Etykiety tekstowe). Faza definiowania wymagań powinna dać odpowiedź na 2 zasadnicze pytania:\n\nco chcemy zmierzyć?\nw jaki sposób chcemy to zmierzyć?\n\n\n\n2.6.2 Gromadzenie danych\nDane są gromadzone z różnych źródeł. Wymogi, co do rodzaju i jakości danych mogą być przekazywane przez analityków do “opiekunów danych”, takich jak personel technologii informacyjnych w organizacji. Dane ponadto mogą być również gromadzone automatycznie z różnego rodzaju czujników znajdujących się w otoczeniu - takich jak kamery drogowe, satelity, urządzenia rejestrujące obraz, dźwięk oraz parametry fizyczne. Kolejną metodą jest również pozyskiwanie danych w drodze wywiadów, gromadzenie ze źródeł internetowych lub bezpośrednio z dokumentacji.\n\n\n2.6.3 Przetwarzanie danych\nZgromadzone dane muszą zostać przetworzone lub zorganizowane w sposób logiczny do analizy. Na przykład, mogą one zostać umieszczone w tabelach w celu dalszej analizy - w arkuszu kalkulacyjnym lub innym oprogramowaniu. Oczyszczanie danych Po fazie przetworzenia i uporządkowania, dane mogą być niekompletne, zawierać duplikaty lub zawierać błędy. Konieczność czyszczenia danych wynika z problemów związanych z wprowadzaniem i przechowywaniem danych. Czyszczenie danych to proces zapobiegania powstawaniu i korygowania wykrytych błędów. Typowe zadania obejmują dopasowywanie rekordów, identyfikowanie nieścisłości, ogólny przegląd jakość istniejących danych, usuwanie duplikatów i segmentację kolumn. Niezwykłe istotne jest też zwracanie uwagi na dane których wartości są powyżej lub poniżej ustalonych wcześniej progów (ekstrema).\n\n\n2.6.4 Właściwa analiza danych\nIstnieje kilka metod, które można wykorzystać do tego celu, na przykład data mining, business intelligence, wizualizacja danych lub badania eksploracyjne. Ta ostatnia metoda jest sposobem analizowania zbiorów informacji w celu określenia ich odrębnych cech. W ten sposób dane mogą zostać wykorzystane do przetestowania pierwotnej hipotezy. Statystyki opisowe to kolejna metoda analizy zebranych informacji. Dane są badane, aby znaleźć najważniejsze ich cechy. W statystykach opisowych analitycy używają kilku podstawowych narzędzi - można użyć średniej lub średniej z zestawu liczb. Pomaga to określić ogólny trend aczkolwiek nie zapewnia to dużej dokładności przy ocenie ogólnego obrazu zebranych danych. W tej fazie ma miejsce również modelowanie i tworzenie formuł matematycznych - stosowane są w celu identyfikacji zależności między zmiennymi, takich jak korelacja lub przyczynowość.\n\n\n2.6.5 Raportowanie i dystrybucja wyników\nTa faza polega na ustalaniu w jakiej formie przekazywać wyniki. Analityk może rozważyć róże techniki wizualizacji danych, aby w sposób wyraźnym i skuteczny przekazać wnioski z analizy odbiorcom. Wizualizacja danych wykorzystuje formy graficzne jak wykresy i tabele. Tabele są przydatne dla użytkownika, który może wyszukiwać konkretne rekordy, podczas gdy wykresy (np. wykresy słupkowe lub liniowe) dają spojrzenie ilościowych na zbiór analizowanych danych.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Trochę teorii...</span>"
    ]
  },
  {
    "objectID": "trocheteorii.html#skąd-brać-dane",
    "href": "trocheteorii.html#skąd-brać-dane",
    "title": "2  Trochę teorii…",
    "section": "2.7 Skąd brać dane?",
    "text": "2.7 Skąd brać dane?\nDarmowa repozytoria danych:\n\nBank danych lokalnych GUS - link\nOtwarte dane - link\nBank Światowy - link\n\nPrzydatne strony:\n\nhttps://www.kaggle.com/\nhttps://archive.ics.uci.edu/ml/index.php",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Trochę teorii...</span>"
    ]
  },
  {
    "objectID": "trocheteorii.html#koncepcja-tidy-data",
    "href": "trocheteorii.html#koncepcja-tidy-data",
    "title": "2  Trochę teorii…",
    "section": "2.8 Koncepcja “Tidy data”",
    "text": "2.8 Koncepcja “Tidy data”\nKoncepcja czyszczenia danych (ang. tidy data):\n\nWICKHAM, Hadley . Tidy Data. Journal of Statistical Software, [S.l.], v. 59, Issue 10, p. 1 - 23, sep. 2014. ISSN 1548-7660. Available at: https://www.jstatsoft.org/v059/i10. Date accessed: 25 oct. 2018. doi:http://dx.doi.org/10.18637/jss.v059.i10.\n\n\n2.8.1 Zasady “czystych danych”\nIdealne dane są zaprezentowane w tabeli:\n\n\n\nImię\nWiek\nWzrost\nKolor oczu\n\n\n\n\nAdam\n26\n167\nBrązowe\n\n\nSylwia\n34\n164\nPiwne\n\n\nTomasz\n42\n183\nNiebieskie\n\n\n\nNa co powinniśmy zwrócić uwagę?\n\njedna obserwacja (jednostka statystyczna) = jeden wiersz w tabeli/macierzy/ramce danych\nwartości danej cechy znajdują się w kolumnach\njeden typ/rodzaj obserwacji w jednej tabeli/macierzy/ramce danych\n\n\n\n2.8.2 Przykłady nieuporządkowanych danych\n\n\n\nImię\nWiek\nWzrost\nBrązowe\nNiebieskie\nPiwne\n\n\n\n\nAdam\n26\n167\n1\n0\n0\n\n\nSylwia\n34\n164\n0\n0\n1\n\n\nTomasz\n42\n183\n0\n1\n0\n\n\n\nNagłowki kolumn muszą odpowiadać cechom, a nie wartościom zmiennych.\n\n\n2.8.3 Długie czy szerokie dane?\nhttps://seaborn.pydata.org/tutorial/data_structure.html#long-form-vs-wide-form-data",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Trochę teorii...</span>"
    ]
  },
  {
    "objectID": "trocheteorii.html#parę-rad-na-dobre-prezentacje",
    "href": "trocheteorii.html#parę-rad-na-dobre-prezentacje",
    "title": "2  Trochę teorii…",
    "section": "2.9 Parę rad na dobre prezentacje",
    "text": "2.9 Parę rad na dobre prezentacje\nEdward Tufte, prof z Yale, https://www.edwardtufte.com/\n\nPrezentuj dane “na bogato”.\nNie ukrywaj danych, pokazuj prawdę.\nNie używaj wykresów śmieciowych.\nPokazuj zmienność danych, a nie projektuj jej.\nWykres ma posiadać jak najmniejszy współczynnik kłamstwa (lie-factor).\nPowerpoint to zło!\n\n\n2.9.1 Współczynnik kłamstwa\nhttps://www.facebook.com/janinadaily/photos/a.1524649467770881/2836063543296127/?paipv=0&eav=AfbVIDx5un8ZOklKI9c-B1jP4nOoNa2QMmJmjoA-291JNNgM1L_NmoCGMS_mJOy4xjo&_rdr\n\nstosunek efektu widocznego na wykresie do efektu wykazywanego przez dane, na podstawie których ten wykres narysowaliśmy.\n\nhttps://infovis-wiki.net/wiki/Lie_Factor\n\n\n2.9.2 Współczynnik kłamstwa\n\n[Tufte, 1991] Edward Tufte, The Visual Display of Quantitative Information, Second Edition, Graphics Press, USA, 1991, p. 57 – 69.\n\\[\\operatorname{LieFactor} = \\frac{\\text{rozmiar efektu widocznego na wykresie}}{\\text{rozmiar efektu wynikającego z danych}}\\]\n\\[\\text{rozmiar efektu} = \\frac{|\\text{druga wartość}-\\text{pierwsza wartość}|}{\\text{pierwsza wartość}}\\]\n\n\\[\\operatorname{LieFactor} = \\frac{\\frac{5.3-0.6}{0.6}}{\\frac{27.5-18}{18}} \\approx 14.8\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Trochę teorii...</span>"
    ]
  },
  {
    "objectID": "trocheteorii.html#jak-tworzyć",
    "href": "trocheteorii.html#jak-tworzyć",
    "title": "2  Trochę teorii…",
    "section": "2.10 Jak tworzyć?",
    "text": "2.10 Jak tworzyć?\n\nhttps://bookdown.org/rudolf_von_ems/jak_sie_nie_dac/stats_graphs.html\nhttps://www.data-to-viz.com/\nhttps://100.datavizproject.com/",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Trochę teorii...</span>"
    ]
  },
  {
    "objectID": "trocheteorii.html#bibliografia",
    "href": "trocheteorii.html#bibliografia",
    "title": "2  Trochę teorii…",
    "section": "2.11 Bibliografia",
    "text": "2.11 Bibliografia\n\nhttps://pl.wikipedia.org/wiki/Wizualizacja\nhttps://mfiles.pl/pl/index.php/Analiza_danych, dostęp online 1.04.2019.\nWalesiak M., Gatnar E., Statystyczna analiza danych z wykorzystaniem programu R, PWN, Warszawa, 2009.\nWasilewska E., Statystyka opisowa od podstaw, Podręcznik z zadaniami, Wydawnictwo SGGW, Warszawa, 2009.\nhttps://en.wikipedia.org/wiki/Cognitive_reflection_test, dostęp online 20.03.2023.\nhttps://qlikblog.pl/edward-tufte-dobre-praktyki-prezentacji-danych/, dostęp online 20.03.2023.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Trochę teorii...</span>"
    ]
  },
  {
    "objectID": "numpy.html",
    "href": "numpy.html",
    "title": "3  NumPy",
    "section": "",
    "text": "3.1 Import biblioteki NumPy\nPodstawowym bytem w bibliotece NumPy jest N-wymiarowa tablica zwana ndarray. Każdy element na tablicy traktowany jest jako typ dtype.\nimport numpy as np\n\n1a = np.array([1, 2, 3])\nprint(\"a:\", a) \n2print(\"typ a:\", type(a))\n3b = np.array([1, 2, 3.0])\nprint(\"b:\", b)\n4c = np.array([[1, 2], [3, 4]])\nprint(\"c:\", c)\n5d = np.array([1, 2, 3], ndmin=2)\nprint(\"d:\", d)\n6e = np.array([1, 2, 3], dtype=complex)\nprint(\"e:\", e)\n7f = np.array(np.mat('1 2; 3 4'))\nprint(\"f:\", f)\n8g = np.array(np.mat('1 2; 3 4'), subok=True)\nprint(\"g:\", g)\nprint(type(g))\n\n\n1\n\nStandardowe domyślne.\n\n2\n\nSprawdzenie typu.\n\n3\n\nJeden z elementów jest innege typu. Tu następuje zatem rozszerzenie do typu “największego”.\n\n4\n\nTu otrzymamy tablicę 2x2.\n\n5\n\nW tej linijce otrzymana będzie tablica 2x1.\n\n6\n\nUstalenie innego typu - większego.\n\n7\n\nSkorzystanie z podtypu macierzowego.\n\n8\n\nZachowanie typu macierzowego.\n\n\n\n\na: [1 2 3]\ntyp a: &lt;class 'numpy.ndarray'&gt;\nb: [1. 2. 3.]\nc: [[1 2]\n [3 4]]\nd: [[1 2 3]]\ne: [1.+0.j 2.+0.j 3.+0.j]\nf: [[1 2]\n [3 4]]\ng: [[1 2]\n [3 4]]\n&lt;class 'numpy.matrix'&gt;",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#import-biblioteki-numpy",
    "href": "numpy.html#import-biblioteki-numpy",
    "title": "3  NumPy",
    "section": "",
    "text": "import numpy as np\n\nnumpy.array(object, dtype=None, *, copy=True, order='K', subok=False, ndmin=0, like=None)\n\nobject - to co ma być wrzucone do tablicy\ndtype - typ\ncopy - czy obiekty mają być skopiowane, domyślne True\norder - sposób układania: C (rzędy), F (kolumny), A, K\nsubok - realizowane przez podklasy (jeśli True), domyślnie False\nndmin - minimalny rozmiar (wymiar) tablicy\nlike - tworzenie na podstawie tablic referencyjnej",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#lista-a-tablica",
    "href": "numpy.html#lista-a-tablica",
    "title": "3  NumPy",
    "section": "3.2 Lista a tablica",
    "text": "3.2 Lista a tablica\n\nimport numpy as np\nimport time\n\nstart_time = time.time()\nmy_arr = np.arange(1000000)\nmy_list = list(range(1000000))\nstart_time = time.time()\nmy_arr2 = my_arr * 2\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\nstart_time = time.time()\nmy_list2 = [x * 2 for x in my_list]\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n\n--- 0.0 seconds ---\n--- 0.05550861358642578 seconds ---",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#atrybuty-tablic-ndarray",
    "href": "numpy.html#atrybuty-tablic-ndarray",
    "title": "3  NumPy",
    "section": "3.3 Atrybuty tablic ndarray",
    "text": "3.3 Atrybuty tablic ndarray\n\n\n\n\n\n\n\nAtrybut\nOpis\n\n\n\n\nshape\nkrotka z informacją liczbę elementów dla każdego z wymiarów\n\n\nsize\nliczba elementów w tablicy (łączna)\n\n\nndim\nliczba wymiarów tablicy\n\n\nnbytes\nliczba bajtów jaką tablica zajmuje w pamięci\n\n\ndtype\ntyp danych\n\n\n\nhttps://numpy.org/doc/stable/reference/arrays.ndarray.html#array-attributes\n\nimport numpy as np\n\ntab1 = np.array([2, -3, 4, -8, 1])\nprint(\"typ:\", type(tab1))\nprint(\"shape:\", tab1.shape)\nprint(\"size:\", tab1.size)\nprint(\"ndim:\", tab1.ndim)\nprint(\"nbytes:\", tab1.nbytes)\nprint(\"dtype:\", tab1.dtype)\n\ntyp: &lt;class 'numpy.ndarray'&gt;\nshape: (5,)\nsize: 5\nndim: 1\nnbytes: 20\ndtype: int32\n\n\n\nimport numpy as np\n\ntab2 = np.array([[2, -3], [4, -8]])\nprint(\"typ:\", type(tab2))\nprint(\"shape:\", tab2.shape)\nprint(\"size:\", tab2.size)\nprint(\"ndim:\", tab2.ndim)\nprint(\"nbytes:\", tab2.nbytes)\nprint(\"dtype:\", tab2.dtype)\n\ntyp: &lt;class 'numpy.ndarray'&gt;\nshape: (2, 2)\nsize: 4\nndim: 2\nnbytes: 16\ndtype: int32\n\n\nNumPy nie wspiera postrzępionych tablic! Poniższy kod wygeneruje błąd:\nimport numpy as np\n\ntab3 = np.array([[2, -3], [4, -8, 5], [3]])",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#typy-danych",
    "href": "numpy.html#typy-danych",
    "title": "3  NumPy",
    "section": "3.4 Typy danych",
    "text": "3.4 Typy danych\nhttps://numpy.org/doc/stable/reference/arrays.scalars.html\nhttps://numpy.org/doc/stable/reference/arrays.dtypes.html#arrays-dtypes-constructing\n\n\n\n\n\n\n\nTypy całkowitoliczbowe\nint,int8,int16,int32,int64\n\n\nTypy całkowitoliczbowe (bez znaku)\nuint,uint8,uint16,uint32,uint64\n\n\nTyp logiczny\nbool\n\n\nTypy zmiennoprzecinkowe\nfloat, float16, float32, float64, float128\n\n\nTypy zmiennoprzecinkowe zespolone\ncomplex, complex64, complex128, complex256\n\n\nNapis\nstr\n\n\n\n\nimport numpy as np\n\ntab = np.array([[2, -3], [4, -8]])\nprint(tab)\ntab2 = np.array([[2, -3], [4, -8]], dtype=int)\nprint(tab2)\ntab3 = np.array([[2, -3], [4, -8]], dtype=float)\nprint(tab3)\ntab4 = np.array([[2, -3], [4, -8]], dtype=complex)\nprint(tab4)\n\n[[ 2 -3]\n [ 4 -8]]\n[[ 2 -3]\n [ 4 -8]]\n[[ 2. -3.]\n [ 4. -8.]]\n[[ 2.+0.j -3.+0.j]\n [ 4.+0.j -8.+0.j]]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#tworzenie-tablic",
    "href": "numpy.html#tworzenie-tablic",
    "title": "3  NumPy",
    "section": "3.5 Tworzenie tablic",
    "text": "3.5 Tworzenie tablic\nnp.array - argumenty rzutowany na tablicę (coś po czym można iterować) - warto sprawdzić rozmiar/kształt\n\nimport numpy as np\n\ntab = np.array([2, -3, 4])\nprint(tab)\nprint(\"size:\", tab.size)\ntab2 = np.array((4, -3, 3, 2))\nprint(tab2)\nprint(\"size:\", tab2.size)\ntab3 = np.array({3, 3, 2, 5, 2})\nprint(tab3)\nprint(\"size:\", tab3.size)\ntab4 = np.array({\"pl\": 344, \"en\": 22})\nprint(tab4)\nprint(\"size:\", tab4.size)\n\n[ 2 -3  4]\nsize: 3\n[ 4 -3  3  2]\nsize: 4\n{2, 3, 5}\nsize: 1\n{'pl': 344, 'en': 22}\nsize: 1\n\n\nnp.zeros - tworzy tablicę wypełnioną zerami\n\nimport numpy as np\n\ntab = np.zeros(4)\nprint(tab)\nprint(tab.shape)\ntab2 = np.zeros([2, 3])\nprint(tab2)\nprint(tab2.shape)\ntab3 = np.zeros([2, 3, 4])\nprint(tab3)\nprint(tab3.shape)\n\n[0. 0. 0. 0.]\n(4,)\n[[0. 0. 0.]\n [0. 0. 0.]]\n(2, 3)\n[[[0. 0. 0. 0.]\n  [0. 0. 0. 0.]\n  [0. 0. 0. 0.]]\n\n [[0. 0. 0. 0.]\n  [0. 0. 0. 0.]\n  [0. 0. 0. 0.]]]\n(2, 3, 4)\n\n\nnp.ones - tworzy tablicę wypełnioną jedynkami (to nie odpowiednik macierzy jednostkowej!)\n\nimport numpy as np\n\ntab = np.ones(4)\nprint(tab)\nprint(tab.shape)\ntab2 = np.ones([2, 3])\nprint(tab2)\nprint(tab2.shape)\ntab3 = np.ones([2, 3, 4])\nprint(tab3)\nprint(tab3.shape)\n\n[1. 1. 1. 1.]\n(4,)\n[[1. 1. 1.]\n [1. 1. 1.]]\n(2, 3)\n[[[1. 1. 1. 1.]\n  [1. 1. 1. 1.]\n  [1. 1. 1. 1.]]\n\n [[1. 1. 1. 1.]\n  [1. 1. 1. 1.]\n  [1. 1. 1. 1.]]]\n(2, 3, 4)\n\n\nnp.diag - tworzy tablicę odpowiadającą macierzy diagonalnej\n\nimport numpy as np\n\nprint(\"tab0\")\ntab0 = np.diag([3, 4, 5])\nprint(tab0)\nprint(\"tab1\")\ntab1 = np.array([[2, 3, 4], [3, -4, 5], [3, 4, -5]])\nprint(tab1)\ntab2 = np.diag(tab1)\nprint(\"tab2\")\nprint(tab2)\ntab3 = np.diag(tab1, k=1)\nprint(\"tab3\")\nprint(tab3)\nprint(\"tab4\")\ntab4 = np.diag(tab1, k=-2)\nprint(tab4)\nprint(\"tab5\")\ntab5 = np.diag(np.diag(tab1))\nprint(tab5)\n\ntab0\n[[3 0 0]\n [0 4 0]\n [0 0 5]]\ntab1\n[[ 2  3  4]\n [ 3 -4  5]\n [ 3  4 -5]]\ntab2\n[ 2 -4 -5]\ntab3\n[3 5]\ntab4\n[3]\ntab5\n[[ 2  0  0]\n [ 0 -4  0]\n [ 0  0 -5]]\n\n\nnp.arange - tablica wypełniona równomiernymi wartościami\nSkładnia: numpy.arange([start, ]stop, [step, ]dtype=None)\nZasada działania jest podobna jak w funkcji range, ale dopuszczamy liczby “z ułamkiem”.\n\nimport numpy as np\n\na = np.arange(3)\nprint(a)\nb = np.arange(3.0)\nprint(b)\nc = np.arange(3, 7)\nprint(c)\nd = np.arange(3, 11, 2)\nprint(d)\ne = np.arange(0, 1, 0.1)\nprint(e)\nf = np.arange(3, 11, 2, dtype=float)\nprint(f)\ng = np.arange(3, 10, 2)\nprint(g)\n\n[0 1 2]\n[0. 1. 2.]\n[3 4 5 6]\n[3 5 7 9]\n[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]\n[3. 5. 7. 9.]\n[3 5 7 9]\n\n\nnp.linspace - tablica wypełniona równomiernymi wartościami wg skali liniowej\n\nimport numpy as np\n\na = np.linspace(2.0, 3.0, num=5)\nprint(a)\nb = np.linspace(2.0, 3.0, num=5, endpoint=False)\nprint(b)\nc = np.linspace(10, 20, num=4)\nprint(c)\nd = np.linspace(10, 20, num=4, dtype=int)\nprint(d)\n\n[2.   2.25 2.5  2.75 3.  ]\n[2.  2.2 2.4 2.6 2.8]\n[10.         13.33333333 16.66666667 20.        ]\n[10 13 16 20]\n\n\n\nnp.logspace - tablica wypełniona wartościami wg skali logarytmicznej\nSkładnia: numpy.logspace(start, stop, num=50, endpoint=True, base=10.0, dtype=None, axis=0)\n\nimport numpy as np\n\na = np.logspace(2.0, 3.0, num=4)\nprint(a)\nb = np.logspace(2.0, 3.0, num=4, endpoint=False)\nprint(b)\nc = np.logspace(2.0, 3.0, num=4, base=2.0)\nprint(c)\n\n[ 100.          215.443469    464.15888336 1000.        ]\n[100.         177.827941   316.22776602 562.34132519]\n[4.         5.0396842  6.34960421 8.        ]\n\n\n\nnp.empty - pusta (niezaincjowana) tablica - konkretne wartości nie są “gwarantowane”\n\nimport numpy as np\n\na = np.empty(3)\nprint(a)\nb = np.empty(3, dtype=int)\nprint(b)\n\n[0. 1. 2.]\n[0 1 2]\n\n\nnp.identity - tablica przypominająca macierz jednostkową\nnp.eye - tablica z jedynkami na przekątnej (pozostałe zera)\n\nimport numpy as np\n\nprint(\"a\")\na = np.identity(4)\nprint(a)\nprint(\"b\")\nb = np.eye(4, k=1)\nprint(b)\nprint(\"c\")\nc = np.eye(4, k=2)\nprint(c)\nprint(\"d\")\nd = np.eye(4, k=-1)\nprint(d)\n\na\n[[1. 0. 0. 0.]\n [0. 1. 0. 0.]\n [0. 0. 1. 0.]\n [0. 0. 0. 1.]]\nb\n[[0. 1. 0. 0.]\n [0. 0. 1. 0.]\n [0. 0. 0. 1.]\n [0. 0. 0. 0.]]\nc\n[[0. 0. 1. 0.]\n [0. 0. 0. 1.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]]\nd\n[[0. 0. 0. 0.]\n [1. 0. 0. 0.]\n [0. 1. 0. 0.]\n [0. 0. 1. 0.]]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#indeksowanie-krojenie",
    "href": "numpy.html#indeksowanie-krojenie",
    "title": "3  NumPy",
    "section": "3.6 Indeksowanie, “krojenie”",
    "text": "3.6 Indeksowanie, “krojenie”\n\nimport numpy as np\n\na = np.array([2, 5, -2, 4, -7, 8, 9, 11, -23, -4, -7, 16, 1])\n1print(\"1:\", a[5])\n2print(\"2:\", a[-2])\n3print(\"3:\", a[3:6])\n4print(\"4:\", a[:])\n5print(\"5:\", a[0:-1])\n6print(\"6:\", a[:5])\n\n\n1\n\nDostęp do elementu o indeksie 5.\n\n2\n\nDostęp do elementu drugiego od tyłu.\n\n3\n\nDostęp do elementów o indeksach od 3 do 5 (włącznie) - zasada przedziałów lewostronnnie domkniętnych, prawostronnie otwartych.\n\n4\n\nDostęp do wszystkich elementów.\n\n5\n\nDostęp do wszystkich elementów z wyłączeniem ostatniego.\n\n6\n\nDostęp od początku do elementu o indeksie 4.\n\n\n\n\n1: 8\n2: 16\n3: [ 4 -7  8]\n4: [  2   5  -2   4  -7   8   9  11 -23  -4  -7  16   1]\n5: [  2   5  -2   4  -7   8   9  11 -23  -4  -7  16]\n6: [ 2  5 -2  4 -7]\n\n\n\nimport numpy as np\n\n1print(\"1:\", a[4:])\n2print(\"2:\", a[4:-1])\n3print(\"3:\", a[4:10:2])\n4print(\"4:\", a[::-1])\n5print(\"5:\", a[::2])\n6print(\"6:\", a[::-2])\n\n\n1\n\nDostęp do elementów od indeksu 4 do końca.\n\n2\n\nDostęp do elementów od indeksu 4 do końca bez ostatniego.\n\n3\n\nDostęp do elementów o indeksach stanowiących ciąg arytmetyczny od 4 do 10 (z czówrką, ale bez dziesiątki) z krokiem równym 2\n\n4\n\nDostęp do elementów od tyłu do początku.\n\n5\n\nDostęp do elementów o indeksach parzystych od początku.\n\n6\n\nDostęp do elementów o indeksach “nieparzystych ujemnych” od początku.\n\n\n\n\n1: [ -7   8   9  11 -23  -4  -7  16   1]\n2: [ -7   8   9  11 -23  -4  -7  16]\n3: [ -7   9 -23]\n4: [  1  16  -7  -4 -23  11   9   8  -7   4  -2   5   2]\n5: [  2  -2  -7   9 -23  -7   1]\n6: [  1  -7 -23   9  -7  -2   2]\n\n\n\nimport numpy as np\n\na = np.array([[3, 4, 5], [-3, 4, 8], [3, 2, 9]])\nb = a[:2, 1:]\nprint(b)\nprint(np.shape(b))\nc = a[1]\nprint(c)\nprint(np.shape(c))\nd = a[1, :]\nprint(d)\nprint(np.shape(d))\n\n[[4 5]\n [4 8]]\n(2, 2)\n[-3  4  8]\n(3,)\n[-3  4  8]\n(3,)\n\n\n\nimport numpy as np\n\na = np.array([[3, 4, 5], [-3, 4, 8], [3, 2, 9]])\ne = a[1:2, :]\nprint(e)\nprint(np.shape(e))\nf = a[:, :2]\nprint(f)\nprint(np.shape(f))\ng = a[1, :2]\nprint(g)\nprint(np.shape(g))\nh = a[1:2, :2]\nprint(h)\nprint(np.shape(h))\n\n[[-3  4  8]]\n(1, 3)\n[[ 3  4]\n [-3  4]\n [ 3  2]]\n(3, 2)\n[-3  4]\n(2,)\n[[-3  4]]\n(1, 2)\n\n\n**Uwaga - takie “krojenie” to tzw “widok”.\n\nimport numpy as np\n\na = np.array([[3, 4, 5], [-3, 4, 8], [3, 2, 9]])\nb = a[1:2, 1:]\nprint(b)\na[1][1] = 9\nprint(a)\nprint(b)\nb[0][0] = -11\nprint(a)\nprint(b)\n\n[[4 8]]\n[[ 3  4  5]\n [-3  9  8]\n [ 3  2  9]]\n[[9 8]]\n[[  3   4   5]\n [ -3 -11   8]\n [  3   2   9]]\n[[-11   8]]\n\n\nNaprawa:\n\nimport numpy as np\n\na = np.array([[3, 4, 5], [-3, 4, 8], [3, 2, 9]])\nb = a[1:2, 1:].copy()\nprint(b)\na[1][1] = 9\nprint(a)\nprint(b)\nb[0][0] = -11\nprint(a)\nprint(b)\n\n[[4 8]]\n[[ 3  4  5]\n [-3  9  8]\n [ 3  2  9]]\n[[4 8]]\n[[ 3  4  5]\n [-3  9  8]\n [ 3  2  9]]\n[[-11   8]]\n\n\nIndeksowanie logiczne (fancy indexing)\n\nimport numpy as np\n\na = np.array([2, 5, -2, 4, -7, 8, 9, 11, -23, -4, -7, 8, 1])\nb = a[np.array([1, 3, 7])]\nprint(b)\nc = a[[1, 3, 7]]\nprint(c)\n\n[ 5  4 11]\n[ 5  4 11]\n\n\n\nimport numpy as np\n\na = np.array([2, 5, -2, 4, -7, 8, 9, 11, -23, -4, -7, 8, 1])\nb = a &gt; 0\nprint(b)\nc = a[a &gt; 0]\nprint(c)\n\n[ True  True False  True False  True  True  True False False False  True\n  True]\n[ 2  5  4  8  9 11  8  1]\n\n\n\nimport numpy as np\n\na = np.array([2, 5, -2, 4, -7, 8, 9, 11, -23, -4, -7, 8, 1])\nb = a[a &gt; 0]\nprint(b)\nb[0] = -5\nprint(a)\nprint(b)\na[1] = 20\nprint(a)\nprint(b)\n\n[ 2  5  4  8  9 11  8  1]\n[  2   5  -2   4  -7   8   9  11 -23  -4  -7   8   1]\n[-5  5  4  8  9 11  8  1]\n[  2  20  -2   4  -7   8   9  11 -23  -4  -7   8   1]\n[-5  5  4  8  9 11  8  1]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#modyfikacja-kształtu-i-rozmiaru",
    "href": "numpy.html#modyfikacja-kształtu-i-rozmiaru",
    "title": "3  NumPy",
    "section": "3.7 Modyfikacja kształtu i rozmiaru",
    "text": "3.7 Modyfikacja kształtu i rozmiaru\nhttps://numpy.org/doc/stable/reference/routines.array-manipulation.html\n\nimport numpy as np\n\nprint(\"a\")\na = np.array([[3, 4, 5], [-3, 4, 8], [3, 2, 9]])\nprint(a)\nprint(\"b\")\nb = np.reshape(a, (1, 9))\nprint(b)\nprint(\"c\")\nc = a.reshape(9)\nprint(c)\n\na\n[[ 3  4  5]\n [-3  4  8]\n [ 3  2  9]]\nb\n[[ 3  4  5 -3  4  8  3  2  9]]\nc\n[ 3  4  5 -3  4  8  3  2  9]\n\n\n\nimport numpy as np\n\nprint(\"a\")\na = np.array([[3, 4, 5], [-3, 4, 8], [3, 2, 9]])\nprint(a)\nprint(\"d\")\nd = a.flatten()\nprint(d)\nprint(\"e\")\ne = a.ravel()\nprint(e)\nprint(\"f\")\nf = np.ravel(a)\nprint(f)\n\na\n[[ 3  4  5]\n [-3  4  8]\n [ 3  2  9]]\nd\n[ 3  4  5 -3  4  8  3  2  9]\ne\n[ 3  4  5 -3  4  8  3  2  9]\nf\n[ 3  4  5 -3  4  8  3  2  9]\n\n\n\nimport numpy as np\n\nprint(\"g\")\ng = [[1, 3, 4]]\nprint(g)\nprint(\"h\")\nh = np.squeeze(g)\nprint(h)\nprint(\"i\")\ni = a.T\nprint(i)\nprint(\"j\")\nj = np.transpose(a)\nprint(j)\n\ng\n[[1, 3, 4]]\nh\n[1 3 4]\ni\n[[ 3 -3  3]\n [ 4  4  2]\n [ 5  8  9]]\nj\n[[ 3 -3  3]\n [ 4  4  2]\n [ 5  8  9]]\n\n\n\nimport numpy as np\n\nprint(\"h\")\nh = [3, -4, 5, -2]\nprint(h)\nprint(\"k\")\nk = np.hstack((h, h, h))\nprint(k)\nprint(\"l\")\nl = np.vstack((h, h, h))\nprint(l)\nprint(\"m\")\nm = np.dstack((h, h, h))\nprint(m)\n\nh\n[3, -4, 5, -2]\nk\n[ 3 -4  5 -2  3 -4  5 -2  3 -4  5 -2]\nl\n[[ 3 -4  5 -2]\n [ 3 -4  5 -2]\n [ 3 -4  5 -2]]\nm\n[[[ 3  3  3]\n  [-4 -4 -4]\n  [ 5  5  5]\n  [-2 -2 -2]]]\n\n\n\nimport numpy as np\n\na = np.array([[1, 2], [3, 4]])\nb = np.array([[5, 6]])\nprint(\"r1\")\nr1 = np.concatenate((a, b))\nprint(r1)\nprint(\"r2\")\nr2 = np.concatenate((a, b), axis=0)\nprint(r2)\nprint(\"r3\")\nr3 = np.concatenate((a, b.T), axis=1)\nprint(r3)\nprint(\"r4\")\nr4 = np.concatenate((a, b), axis=None)\nprint(r4)\n\nr1\n[[1 2]\n [3 4]\n [5 6]]\nr2\n[[1 2]\n [3 4]\n [5 6]]\nr3\n[[1 2 5]\n [3 4 6]]\nr4\n[1 2 3 4 5 6]\n\n\n\nimport numpy as np\n\na = np.array([[1, 2], [3, 4]])\nprint(\"r1\")\nr1 = np.resize(a, (2, 3))\nprint(r1)\nprint(\"r2\")\nr2 = np.resize(a, (1, 4))\nprint(r2)\nprint(\"r3\")\nr3 = np.resize(a, (2, 4))\nprint(r3)\n\nr1\n[[1 2 3]\n [4 1 2]]\nr2\n[[1 2 3 4]]\nr3\n[[1 2 3 4]\n [1 2 3 4]]\n\n\n\nimport numpy as np\n\na = np.array([[1, 2], [3, 4]])\nb = np.array([[5, 6]])\nprint(\"r1\")\nr1 = np.append(a, b)\nprint(r1)\nprint(\"r2\")\nr2 = np.append(a, b, axis=0)\nprint(r2)\n\nr1\n[1 2 3 4 5 6]\nr2\n[[1 2]\n [3 4]\n [5 6]]\n\n\n\nimport numpy as np\n\na = np.array([[1, 2], [3, 7]])\nprint(\"r1\")\nr1 = np.insert(a, 1, 4)\nprint(r1)\nprint(\"r2\")\nr2 = np.insert(a, 2, 4)\nprint(r2)\nprint(\"r3\")\nr3 = np.insert(a, 1, 4, axis=0)\nprint(r3)\nprint(\"r4\")\nr4 = np.insert(a, 1, 4, axis=1)\nprint(r4)\n\nr1\n[1 4 2 3 7]\nr2\n[1 2 4 3 7]\nr3\n[[1 2]\n [4 4]\n [3 7]]\nr4\n[[1 4 2]\n [3 4 7]]\n\n\n\nimport numpy as np\n\na = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\nprint(\"r1\")\nr1 = np.delete(a, 1, axis=1)\nprint(r1)\nprint(\"r2\")\nr2 = np.delete(a, 2, axis=0)\nprint(r2)\n\nr1\n[[ 1  3  4]\n [ 5  7  8]\n [ 9 11 12]]\nr2\n[[1 2 3 4]\n [5 6 7 8]]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#broadcasting",
    "href": "numpy.html#broadcasting",
    "title": "3  NumPy",
    "section": "3.8 Broadcasting",
    "text": "3.8 Broadcasting\nRozważane warianty są przykładowe.\nWariant 1 - skalar-tablica - wykonanie operacji na każdym elemencie tablicy\n\nimport numpy as np\n\na = np.array([[1, 2], [5, 6], [9, 10]])\nb = a + 4\nprint(b)\nc = 2 ** a\nprint(c)\n\n[[ 5  6]\n [ 9 10]\n [13 14]]\n[[   2    4]\n [  32   64]\n [ 512 1024]]\n\n\n\nWariant 2 - dwie tablice - “gdy jedna z tablic może być rozszerzona” (oba wymiary są równe lub jeden z nich jest równy 1)\nhttps://numpy.org/doc/stable/user/basics.broadcasting.html\n\nimport numpy as np\n\na = np.array([[1, 2], [5, 6]])\nb = np.array([9, 2])\nr1 = a + b\nprint(r1)\nr2 = a / b\nprint(r2)\nc = np.array([[4], [-2]])\nr3 = a + c\nprint(r3)\nr4 = c / a\nprint(r4)\n\n[[10  4]\n [14  8]]\n[[0.11111111 1.        ]\n [0.55555556 3.        ]]\n[[5 6]\n [3 4]]\n[[ 4.          2.        ]\n [-0.4        -0.33333333]]\n\n\n\nWariant 3 - “kolumna” i “wiersz”\n\nimport numpy as np\n\na = np.array([[5, 2, -3]]).T\nb = np.array([3, -2, 1, 2, 4])\nprint(a+b)\nprint(b+a)\nprint(a*b)\n\n[[ 8  3  6  7  9]\n [ 5  0  3  4  6]\n [ 0 -5 -2 -1  1]]\n[[ 8  3  6  7  9]\n [ 5  0  3  4  6]\n [ 0 -5 -2 -1  1]]\n[[ 15 -10   5  10  20]\n [  6  -4   2   4   8]\n [ -9   6  -3  -6 -12]]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#funkcje-uniwersalne",
    "href": "numpy.html#funkcje-uniwersalne",
    "title": "3  NumPy",
    "section": "3.9 Funkcje uniwersalne",
    "text": "3.9 Funkcje uniwersalne\nhttps://numpy.org/doc/stable/reference/ufuncs.html#methods",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#statystyka-i-agregacja",
    "href": "numpy.html#statystyka-i-agregacja",
    "title": "3  NumPy",
    "section": "3.10 Statystyka i agregacja",
    "text": "3.10 Statystyka i agregacja\n\n\n\n\n\n\n\nFunkcja\nOpis\n\n\n\n\nnp.mean\nŚrednia wszystkich wartości w tablicy.\n\n\nnp.std\nOdchylenie standardowe.\n\n\nnp.var\nWariancja.\n\n\nnp.sum\nSuma wszystkich elementów.\n\n\nnp.prod\nIloczyn wszystkich elementów.\n\n\nnp.cumsum\nSkumulowana suma wszystkich elementów.\n\n\nnp.cumprod\nSkumulowany iloczyn wszystkich elementów.\n\n\nnp.min,np.max\nMinimalna/maksymalna wartość w tablicy.\n\n\nnp.argmin, np.argmax\nIndeks minimalnej/maksymalnej wartości w tablicy.\n\n\nnp.all\nSprawdza czy wszystki elementy są różne od zera.\n\n\nnp.any\nSprawdza czy co najmniej jeden z elementów jest różny od zera.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#wyrażenia-warunkowe",
    "href": "numpy.html#wyrażenia-warunkowe",
    "title": "3  NumPy",
    "section": "3.11 Wyrażenia warunkowe",
    "text": "3.11 Wyrażenia warunkowe\nhttps://numpy.org/doc/stable/reference/generated/numpy.where https://numpy.org/doc/stable/reference/generated/numpy.choose https://numpy.org/doc/stable/reference/generated/numpy.select https://numpy.org/doc/stable/reference/generated/numpy.nonzero",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#działania-na-zbiorach",
    "href": "numpy.html#działania-na-zbiorach",
    "title": "3  NumPy",
    "section": "3.12 Działania na zbiorach",
    "text": "3.12 Działania na zbiorach\nhttps://numpy.org/doc/stable/reference/routines.set.html",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#operacje-tablicowe",
    "href": "numpy.html#operacje-tablicowe",
    "title": "3  NumPy",
    "section": "3.13 Operacje tablicowe",
    "text": "3.13 Operacje tablicowe\nhttps://numpy.org/doc/stable/reference/generated/numpy.transpose\nhttps://numpy.org/doc/stable/reference/generated/numpy.flip https://numpy.org/doc/stable/reference/generated/numpy.fliplr https://numpy.org/doc/stable/reference/generated/numpy.flipud\nhttps://numpy.org/doc/stable/reference/generated/numpy.sort",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#alegbra-liniowa",
    "href": "numpy.html#alegbra-liniowa",
    "title": "3  NumPy",
    "section": "3.14 Alegbra liniowa",
    "text": "3.14 Alegbra liniowa\nhttps://numpy.org/doc/stable/reference/routines.linalg.html",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#funkcja-na-stringach",
    "href": "numpy.html#funkcja-na-stringach",
    "title": "3  NumPy",
    "section": "3.15 Funkcja na stringach",
    "text": "3.15 Funkcja na stringach\nhttps://numpy.org/doc/stable/reference/routines.char.html",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#data-i-czas",
    "href": "numpy.html#data-i-czas",
    "title": "3  NumPy",
    "section": "3.16 Data i czas",
    "text": "3.16 Data i czas\nhttps://numpy.org/doc/stable/reference/arrays.datetime.html",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#pseudolosowe",
    "href": "numpy.html#pseudolosowe",
    "title": "3  NumPy",
    "section": "3.17 Pseudolosowe",
    "text": "3.17 Pseudolosowe\nhttps://numpy.org/doc/stable/reference/random/index.html\nBibliografia:\n\nDokumentacja biblioteki, https://numpy.org/doc/stable/, dostęp online 5.03.2021.\nRobert Jahansson, Matematyczny Python. Obliczenia naukowe i analiza danych z użyciem NumPy, SciPy i Matplotlib, Wyd. Helion, 2021.\nhttps://www.tutorialspoint.com/numpy/index.htm, dostęp online 20.03.2019.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy-zadania.html",
    "href": "numpy-zadania.html",
    "title": "4  NumPy - zadania",
    "section": "",
    "text": "Utwórz tablicę NumPy o wymiarach 3x2, a następnie zmień jej kształt na 2x3 bez zmiany danych.\nDla danej tablicy NumPy zawierającej co najmniej 10 elementów, wykonaj indeksowanie, aby uzyskać trzeci element, a następnie “krojenie”, aby uzyskać elementy od trzeciego do szóstego.\nUtwórz tablicę zawierającą 10 równo rozmieszczonych punktów między 0 a 100. Następnie, wykorzystując utworzoną tablicę, oblicz wartości funkcji kwadratowej \\(y = x^2\\) dla każdego punktu. Wyniki zapisz w nowej tablicy.\nWygeneruj tablicę zawierającą 20 punktów równomiernie rozłożonych w zakresie od \\(\\pi\\) do \\(2\\pi\\) i użyj tej tablicy do obliczenia i wyświetlenia sinusa dla każdego punktu. Wyniki zapisz w osobnej tablicy.\nStwórz tablicę składającą się z 15 punktów równomiernie rozłożonych między -5 a 5. Następnie, na podstawie tej tablicy, utwórz dwie nowe tablice: jedną zawierającą wartości funkcji eksponencjalnej \\(e^x\\) dla każdego z punktów, a drugą zawierającą logarytm naturalny dla tych punktów, gdzie punkty równoznaczne z wartością mniejszą lub równą 0 są pomijane.\nStwórz tablicę logArray, używając funkcji logspace, która zawiera 30 punktów rozłożonych logarytmicznie między \\(10^1\\) a \\(10^5\\). Następnie oblicz średnią wartość wszystkich elementów w tej tablicy.\nWygeneruj tablicę frequencies, korzystając z funkcji logspace, aby otrzymać 25 punktów logarytmicznie równomiernie rozłożonych między częstotliwościami \\(10^2\\) Hz a \\(10^6\\) Hz. Użyj tej tablicy do symulacji wartości pewnego sygnału w zależności od częstotliwości i zapisz wyniki w nowej tablicy signalValues.\nKorzystając z funkcji logspace, utwórz tablicę resistances reprezentującą wartości rezystancji, które są rozłożone logarytmicznie w zakresie od \\(1\\Omega\\) do \\(1M\\Omega\\) włącznie, z 40 punktami.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy - zadania</span>"
    ]
  },
  {
    "objectID": "pandas.html",
    "href": "pandas.html",
    "title": "5  Pandas",
    "section": "",
    "text": "5.1 Podstawowe byty\nSeria - Series\nRamka danych - DataFrame\nimport pandas as pd\nimport numpy as np\n\ns = pd.Series([3, -5, 7, 4])\nprint(s)\nprint(\"values\")\nprint(s.values)\nprint(type(s.values))\nt = np.sort(s.values)\nprint(t)\nprint(s.index)\nprint(type(s.index))\n\n0    3\n1   -5\n2    7\n3    4\ndtype: int64\nvalues\n[ 3 -5  7  4]\n&lt;class 'numpy.ndarray'&gt;\n[-5  3  4  7]\nRangeIndex(start=0, stop=4, step=1)\n&lt;class 'pandas.core.indexes.range.RangeIndex'&gt;\nimport pandas as pd\nimport numpy as np\n\ns = pd.Series([3, -5, 7, 4], index=['a', 'b', 'c', 'd'])\nprint(s)\nprint(s['b'])\ns['b'] = 8\nprint(s)\nprint(s[s &gt; 5])\nprint(s * 2)\nprint(np.sin(s))\n\na    3\nb   -5\nc    7\nd    4\ndtype: int64\n-5\na    3\nb    8\nc    7\nd    4\ndtype: int64\nb    8\nc    7\ndtype: int64\na     6\nb    16\nc    14\nd     8\ndtype: int64\na    0.141120\nb    0.989358\nc    0.656987\nd   -0.756802\ndtype: float64\nimport pandas as pd\n\nd = {'key1': 350, 'key2': 700, 'key3': 70}\ns = pd.Series(d)\nprint(s)\n\nkey1    350\nkey2    700\nkey3     70\ndtype: int64\nimport pandas as pd\n\nd = {'key1': 350, 'key2': 700, 'key3': 70}\nk = ['key0', 'key2', 'key3', 'key1']\ns = pd.Series(d, index=k)\nprint(s)\npd.isnull(s)\npd.notnull(s)\ns.isnull()\ns.notnull()\ns.name = \"Wartosc\"\ns.index.name = \"Klucz\"\nprint(s)\n\nkey0      NaN\nkey2    700.0\nkey3     70.0\nkey1    350.0\ndtype: float64\nKlucz\nkey0      NaN\nkey2    700.0\nkey3     70.0\nkey1    350.0\nName: Wartosc, dtype: float64\nimport pandas as pd\n\ndata = {'Country': ['Belgium', 'India', 'Brazil'],\n        'Capital': ['Brussels', 'New Delhi', 'Brasília'],\n        'Population': [11190846, 1303171035, 207847528]}\nframe = pd.DataFrame(data)\nprint(frame)\ndf = pd.DataFrame(data, columns=['Country', 'Population', 'Capital'])\nprint(df)\n\n   Country    Capital  Population\n0  Belgium   Brussels    11190846\n1    India  New Delhi  1303171035\n2   Brazil   Brasília   207847528\n   Country  Population    Capital\n0  Belgium    11190846   Brussels\n1    India  1303171035  New Delhi\n2   Brazil   207847528   Brasília\nimport pandas as pd\n\ndata = {'Country': ['Belgium', 'India', 'Brazil'],\n        'Capital': ['Brussels', 'New Delhi', 'Brasília'],\n        'Population': [11190846, 1303171035, 207847528]}\ndf = pd.DataFrame(data, columns=['Country', 'Population', 'Capital'])\nprint(df.iloc[[0], [0]])\nprint(\"--\")\nprint(df.loc[[0], ['Country']])\nprint(\"--\")\nprint(df.loc[2])\nprint(\"--\")\nprint(df.loc[:, 'Capital'])\nprint(\"--\")\nprint(df.loc[1, 'Capital'])\n\n   Country\n0  Belgium\n--\n   Country\n0  Belgium\n--\nCountry          Brazil\nPopulation    207847528\nCapital        Brasília\nName: 2, dtype: object\n--\n0     Brussels\n1    New Delhi\n2     Brasília\nName: Capital, dtype: object\n--\nNew Delhi\nimport pandas as pd\n\ndata = {'Country': ['Belgium', 'India', 'Brazil'],\n        'Capital': ['Brussels', 'New Delhi', 'Brasília'],\n        'Population': [11190846, 1303171035, 207847528]}\ndf = pd.DataFrame(data, columns=['Country', 'Population', 'Capital'])\nprint(df['Population'])       \nprint(\"--\")\nprint(df[df['Population'] &gt; 1200000000])\nprint(\"--\")\nprint(df.drop('Country', axis=1))\nprint(\"--\")\n\n0      11190846\n1    1303171035\n2     207847528\nName: Population, dtype: int64\n--\n  Country  Population    Capital\n1   India  1303171035  New Delhi\n--\n   Population    Capital\n0    11190846   Brussels\n1  1303171035  New Delhi\n2   207847528   Brasília\n--\nimport pandas as pd\n\ndata = {'Country': ['Belgium', 'India', 'Brazil'],\n        'Capital': ['Brussels', 'New Delhi', 'Brasília'],\n        'Population': [11190846, 1303171035, 207847528]}\ndf = pd.DataFrame(data, columns=['Country', 'Population', 'Capital'])\nprint(\"Shape:\", df.shape)\nprint(\"--\")\nprint(\"Index:\", df.index)\nprint(\"--\")\nprint(\"columns:\", df.columns)\nprint(\"--\")\ndf.info()\nprint(\"--\")\nprint(df.count())\n\nShape: (3, 3)\n--\nIndex: RangeIndex(start=0, stop=3, step=1)\n--\ncolumns: Index(['Country', 'Population', 'Capital'], dtype='object')\n--\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 3 entries, 0 to 2\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Country     3 non-null      object\n 1   Population  3 non-null      int64 \n 2   Capital     3 non-null      object\ndtypes: int64(1), object(2)\nmemory usage: 204.0+ bytes\n--\nCountry       3\nPopulation    3\nCapital       3\ndtype: int64",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "pandas.html#podstawowe-byty",
    "href": "pandas.html#podstawowe-byty",
    "title": "5  Pandas",
    "section": "",
    "text": "loc:\n\n\nTo metoda indeksowania oparta na etykietach, co oznacza, że używa nazw etykiet kolumn i indeksów wierszy do wyboru danych.\nDziała na podstawie etykiet indeksu oraz etykiet kolumny, co pozwala na wygodniejsze filtrowanie danych.\nObsługuje zarówno jednostkowe etykiety, jak i zakresy etykiet.\nDziała również z etykietami nieliczbowymi.\nPrzykład użycia: df.loc[1:3, ['A', 'B']] - zwraca wiersze od indeksu 1 do 3 (włącznie) oraz kolumny ‘A’ i ‘B’.\n\n\niloc:\n\n\nTo metoda indeksowania oparta na pozycji, co oznacza, że używa liczbowych indeksów kolumn i wierszy do wyboru danych.\nDziała na podstawie liczbowych indeksów zarówno dla wierszy, jak i kolumn.\nObsługuje jednostkowe indeksy oraz zakresy indeksów.\nW przypadku używania zakresów indeksów, zakres jest półotwarty, co oznacza, że prawy kraniec nie jest uwzględniany.\nPrzykład użycia: df.iloc[1:3, 0:2] - zwraca wiersze od indeksu 1 do 3 (bez 3) oraz kolumny od indeksu 0 do 2 (bez 2).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "pandas.html#uzupełnianie-braków",
    "href": "pandas.html#uzupełnianie-braków",
    "title": "5  Pandas",
    "section": "5.2 Uzupełnianie braków",
    "text": "5.2 Uzupełnianie braków\n\nimport pandas as pd\n\ns = pd.Series([3, -5, 7, 4], index=['a', 'b', 'c', 'd'])\ns2 = pd.Series([7, -2, 3], index=['a', 'c', 'd'])\nprint(s + s2)\nprint(\"--\")\nprint(s.add(s2, fill_value=0))\nprint(\"--\")\nprint(s.mul(s2, fill_value=2))\n\na    10.0\nb     NaN\nc     5.0\nd     7.0\ndtype: float64\n--\na    10.0\nb    -5.0\nc     5.0\nd     7.0\ndtype: float64\n--\na    21.0\nb   -10.0\nc   -14.0\nd    12.0\ndtype: float64",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "pandas.html#obsługa-plików-csv",
    "href": "pandas.html#obsługa-plików-csv",
    "title": "5  Pandas",
    "section": "5.3 Obsługa plików csv",
    "text": "5.3 Obsługa plików csv\nFunkcja pandas.read_csv\nDokumentacja: link\nWybrane argumenty:\n\nfilepath - ścieżka dostępu\nsep=_NoDefault.no_default, delimiter=None - separator\nheader='infer' - nagłówek - domyślnie nazwy kolumn, ew. header=None oznacza brak nagłówka\nindex_col=None - ustalenie kolumny na indeksy (nazwy wierszy)\nthousands=None - separator tysięczny\ndecimal='.' - separator dziesiętny\n\nZapis pandas.DataFrame.to_csv\nDokumentacja: link",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "pandas.html#obsługa-plików-z-excela",
    "href": "pandas.html#obsługa-plików-z-excela",
    "title": "5  Pandas",
    "section": "5.4 Obsługa plików z Excela",
    "text": "5.4 Obsługa plików z Excela\nFunkcja pandas.read_excel\nhttps://pandas.pydata.org/docs/reference/api/pandas.read_excel.html\n** Ważne: trzeba zainstalować bibliotekę openpyxl do importu .xlsx oraz xlrd do importu .xls (nie trzeba ich importować w kodzie jawnie w większości wypadków)\nWybrane argumenty:\n\nio - ścieżka dostępu\nsheet_name=0 - nazwa arkusza\nheader='infer' - nagłówek - domyślnie nazwy kolumn, ew. header=None oznacza brak nagłówka\nindex_col=None - ustalenie kolumny na indeksy (nazwy wierszy)\nthousands=None - separator tysięczny\ndecimal='.' - separator dziesiętny",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "pandas.html#repozytorium-z-testowymi-plikami",
    "href": "pandas.html#repozytorium-z-testowymi-plikami",
    "title": "5  Pandas",
    "section": "5.5 Repozytorium z testowymi plikami",
    "text": "5.5 Repozytorium z testowymi plikami\n\nhttps://github.com/pjastr/SamleTestFilesVD",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "pandas.html#operacje-manipulacyjne",
    "href": "pandas.html#operacje-manipulacyjne",
    "title": "5  Pandas",
    "section": "5.6 Operacje manipulacyjne",
    "text": "5.6 Operacje manipulacyjne\nŚciągawka https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n\nmerge\n\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html\nFunkcja merge służy do łączenia dwóch ramek danych wzdłuż wspólnej kolumny, podobnie jak operacje JOIN w SQL.\nDataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)\nGdzie:\n\nright: ramka danych, którą chcesz dołączyć do oryginalnej ramki danych.\nhow: określa typ łączenia. Dostępne są cztery typy: ‘inner’, ‘outer’, ‘left’ i ‘right’. ‘inner’ to domyślna wartość, która zwraca tylko te wiersze, które mają pasujące klucze w obu ramkach danych.\non: nazwa lub lista nazw, które mają być używane do łączenia. Musi to być nazwa występująca zarówno w oryginalnej, jak i prawej ramce danych.\nleft_on i right_on: nazwy kolumn w lewej i prawej ramce danych, które mają być używane do łączenia. Można to użyć, jeśli nazwy kolumn nie są takie same.\nleft_index i right_index: czy indeksy z lewej i prawej ramki danych mają być używane do łączenia.\nsort: czy wynikowa ramka danych ma być posortowany według łączonych kluczy.\nsuffixes: sufiksy, które mają być dodane do nazw kolumn, które nachodzą na siebie. Domyślnie to (’_x’, ’_y’).\ncopy: czy zawsze kopiować dane, nawet jeśli nie są potrzebne.\nindicator: dodaj kolumnę do wynikowej ramki danych, która pokazuje źródło każdego wiersza.\nvalidate: sprawdź, czy określone zasady łączenia są spełnione.\n\n\nimport pandas as pd\n\ndf1 = pd.DataFrame({\n    'A': ['A0', 'A1', 'A2', 'A3'],\n    'B': ['B0', 'B1', 'B2', 'B3'],\n    'key': ['K0', 'K1', 'K0', 'K1']\n})\n\ndf2 = pd.DataFrame({\n    'C': ['C0', 'C1'],\n    'D': ['D0', 'D1']},\n    index=['K0', 'K1']\n)\n\nprint(df1)\nprint(df2)\nmerged_df = df1.merge(df2, left_on='key', right_index=True)\nprint(merged_df)\n\n    A   B key\n0  A0  B0  K0\n1  A1  B1  K1\n2  A2  B2  K0\n3  A3  B3  K1\n     C   D\nK0  C0  D0\nK1  C1  D1\n    A   B key   C   D\n0  A0  B0  K0  C0  D0\n1  A1  B1  K1  C1  D1\n2  A2  B2  K0  C0  D0\n3  A3  B3  K1  C1  D1\n\n\n\nimport pandas as pd\n\ndf1 = pd.DataFrame({\n    'key': ['K0', 'K1', 'K2', 'K3'],\n    'A': ['A0', 'A1', 'A2', 'A3'],\n    'B': ['B0', 'B1', 'B2', 'B3']\n})\n\ndf2 = pd.DataFrame({\n    'key': ['K0', 'K1', 'K4', 'K5'],\n    'C': ['C0', 'C1', 'C2', 'C3'],\n    'D': ['D0', 'D1', 'D2', 'D3']\n})\n\nprint(df1)\n\nprint(df2)\n\ninner_merged_df = df1.merge(df2, how='inner', on='key', suffixes=('_left', '_right'), indicator=True)\nouter_merged_df = df1.merge(df2, how='outer', on='key', suffixes=('_left', '_right'), indicator=True)\nleft_merged_df = df1.merge(df2, how='left', on='key', suffixes=('_left', '_right'), indicator=True)\nright_merged_df = df1.merge(df2, how='right', on='key', suffixes=('_left', '_right'), indicator=True)\n\nprint(\"Inner join\")\nprint(inner_merged_df)\n\nprint(\"Outer join\")\nprint(outer_merged_df)\n\nprint(\"Left join\")\nprint(left_merged_df)\n\nprint(\"Right join\")\nprint(right_merged_df)\n\n  key   A   B\n0  K0  A0  B0\n1  K1  A1  B1\n2  K2  A2  B2\n3  K3  A3  B3\n  key   C   D\n0  K0  C0  D0\n1  K1  C1  D1\n2  K4  C2  D2\n3  K5  C3  D3\nInner join\n  key   A   B   C   D _merge\n0  K0  A0  B0  C0  D0   both\n1  K1  A1  B1  C1  D1   both\nOuter join\n  key    A    B    C    D      _merge\n0  K0   A0   B0   C0   D0        both\n1  K1   A1   B1   C1   D1        both\n2  K2   A2   B2  NaN  NaN   left_only\n3  K3   A3   B3  NaN  NaN   left_only\n4  K4  NaN  NaN   C2   D2  right_only\n5  K5  NaN  NaN   C3   D3  right_only\nLeft join\n  key   A   B    C    D     _merge\n0  K0  A0  B0   C0   D0       both\n1  K1  A1  B1   C1   D1       both\n2  K2  A2  B2  NaN  NaN  left_only\n3  K3  A3  B3  NaN  NaN  left_only\nRight join\n  key    A    B   C   D      _merge\n0  K0   A0   B0  C0  D0        both\n1  K1   A1   B1  C1  D1        both\n2  K4  NaN  NaN  C2  D2  right_only\n3  K5  NaN  NaN  C3  D3  right_only\n\n\n\njoin\n\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html\nMetoda join jest używana do łączenia dwóch ramek danych wzdłuż osi.\nPodstawowe użycie tej metody wygląda następująco:\nDataFrame.join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False)\nGdzie:\n\nother: ramka danych, którą chcesz dołączyć do oryginalnej ramki danych.\non: nazwa lub lista nazw kolumn w oryginalnej ramxce danych, do których chcesz dołączyć.\nhow: określa typ łączenia. Dostępne są cztery typy: ‘inner’, ‘outer’, ‘left’ i ‘right’. ‘left’ to domyślna wartość, która zwraca wszystkie wiersze z oryginalnej ramki danych i pasujące wiersze z drugiej ramki danych. Wartości są uzupełniane wartością NaN, jeśli nie ma dopasowania.\nlsuffix i rsuffix: sufiksy do dodania do kolumn, które się powtarzają. Domyślnie jest to puste.\nsort: czy sortować dane według klucza.\n\n\nimport pandas as pd\n\ndf1 = pd.DataFrame({\n    'A': ['A0', 'A1', 'A2'],\n    'B': ['B0', 'B1', 'B2']},\n    index=['K0', 'K1', 'K2']\n)\n\ndf2 = pd.DataFrame({\n    'C': ['C0', 'C2', 'C3'],\n    'D': ['D0', 'D2', 'D3']},\n    index=['K0', 'K2', 'K3']\n)\n\nprint(df1)\n\nprint(df2)\n\njoined_df = df1.join(df2)\nprint(joined_df)\n\n     A   B\nK0  A0  B0\nK1  A1  B1\nK2  A2  B2\n     C   D\nK0  C0  D0\nK2  C2  D2\nK3  C3  D3\n     A   B    C    D\nK0  A0  B0   C0   D0\nK1  A1  B1  NaN  NaN\nK2  A2  B2   C2   D2\n\n\n\nconcat\n\nhttps://pandas.pydata.org/docs/reference/api/pandas.concat.html\nMetoda concat jest używana do łączenia dwóch lub więcej ramek danych wzdłuż określonej osi.\nPodstawowe użycie tej metody wygląda następująco:\npandas.concat(objs, axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=False, copy=True)\nGdzie:\n\nobjs: sekwencja ramek danych, które chcesz połączyć.\naxis: oś, wzdłuż której chcesz łączyć ramki danych. Domyślnie to 0 (łączenie wierszy, pionowo), ale można także ustawić na 1 (łączenie kolumn, poziomo).\njoin: określa typ łączenia. Dostępne są dwa typy: ‘outer’ i ‘inner’. ‘outer’ to domyślna wartość, która zwraca wszystkie kolumny z każdej ramki danych. ‘inner’ zwraca tylko te kolumny, które są wspólne dla wszystkich ramek danych.\nignore_index: jeśli ustawione na True, nie używa indeksów z ramek danych do tworzenia indeksu w wynikowej ramce danych. Zamiast tego tworzy nowy indeks od 0 do n-1.\nkeys: wartości do skojarzenia z obiektami.\nlevels: określone indeksy dla nowej ramki danych.\nnames: nazwy dla poziomów indeksów (jeśli są wielopoziomowe).\nverify_integrity: sprawdza, czy nowy, skonkatenowana ramka danych nie ma powtarzających się indeksów.\nsort: czy sortować niekonkatenacyjną oś (np. indeksy, jeśli axis=0), niezależnie od danych.\ncopy: czy zawsze kopiować dane, nawet jeśli nie są potrzebne.\n\n\nimport pandas as pd\n\ndf1 = pd.DataFrame({\n    'A': ['A0', 'A1', 'A2'],\n    'B': ['B0', 'B1', 'B2']\n})\n\ndf2 = pd.DataFrame({\n    'A': ['A3', 'A4', 'A5'],\n    'B': ['B3', 'B4', 'B5']\n})\n\nprint(df1)\n\nprint(df2)\n\nconcatenated_df = pd.concat([df1, df2], ignore_index=True)\nprint(concatenated_df)\n\n    A   B\n0  A0  B0\n1  A1  B1\n2  A2  B2\n    A   B\n0  A3  B3\n1  A4  B4\n2  A5  B5\n    A   B\n0  A0  B0\n1  A1  B1\n2  A2  B2\n3  A3  B3\n4  A4  B4\n5  A5  B5\n\n\n\nimport pandas as pd\n\ndf1 = pd.DataFrame({\n    'A': ['A0', 'A1', 'A2'],\n    'B': ['B0', 'B1', 'B2']\n})\n\ndf2 = pd.DataFrame({\n    'C': ['C0', 'C1', 'C2'],\n    'D': ['D0', 'D1', 'D2']\n})\n\nprint(df1)\n\nprint(df2)\n\nconcatenated_df_axis1 = pd.concat([df1, df2], axis=1)\nconcatenated_df_keys = pd.concat([df1, df2], keys=['df1', 'df2'])\n\nprint(concatenated_df_axis1)\nprint(concatenated_df_keys)\n\n    A   B\n0  A0  B0\n1  A1  B1\n2  A2  B2\n    C   D\n0  C0  D0\n1  C1  D1\n2  C2  D2\n    A   B   C   D\n0  A0  B0  C0  D0\n1  A1  B1  C1  D1\n2  A2  B2  C2  D2\n         A    B    C    D\ndf1 0   A0   B0  NaN  NaN\n    1   A1   B1  NaN  NaN\n    2   A2   B2  NaN  NaN\ndf2 0  NaN  NaN   C0   D0\n    1  NaN  NaN   C1   D1\n    2  NaN  NaN   C2   D2\n\n\n\npivot\n\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html\n\nMetoda pivot jest używana do przekształcenia danych z formatu “długiego” do “szerokiego”.\nPodstawowe użycie tej metody wygląda następująco:\nDataFrame.pivot(index=None, columns=None, values=None)\nGdzie:\n\nindex: nazwa kolumny lub lista nazw kolumn, które mają stać się indeksem w nowej ramce danych.\ncolumns: nazwa kolumny, z której unikalne wartości mają stać się kolumnami w nowej ramce danych.\nvalues: nazwa kolumny lub lista nazw kolumn, które mają stać się wartościami dla nowych kolumn w nowej ramce danych.\n\n\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'foo': ['one', 'one', 'one', 'two', 'two', 'two'],\n    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n    'baz': [1, 2, 3, 4, 5, 6],\n    'zoo': ['x', 'y', 'z', 'q', 'w', 't'],\n})\n\nprint(df)\n\npivot_df = df.pivot(index='foo', columns='bar', values='baz')\nprint(pivot_df)\n\n   foo bar  baz zoo\n0  one   A    1   x\n1  one   B    2   y\n2  one   C    3   z\n3  two   A    4   q\n4  two   B    5   w\n5  two   C    6   t\nbar  A  B  C\nfoo         \none  1  2  3\ntwo  4  5  6\n\n\n\nwide_to_long\n\nhttps://pandas.pydata.org/docs/reference/api/pandas.wide_to_long.html\n\nmelt\n\n\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.melt.html\nFunkcja melt służy do przekształcania danych z formatu szerokiego na długi.\nPodstawowe użycie tej metody wygląda następująco:\npandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)\nGdzie:\n\nframe: ramka danych, którą chcesz przetworzyć.\nid_vars: kolumna(y), które chcesz zachować jako identyfikatory. Te kolumny nie będą zmieniane.\nvalue_vars: kolumna(y), które chcesz przekształcić na pary klucz-wartość. Jeżeli nie jest podane, wszystkie kolumny nie będące id_vars zostaną użyte.\nvar_name: nazwa nowej kolumny, która będzie zawierała nazwy kolumn przekształconych na pary klucz-wartość. Domyślnie to ‘variable’.\nvalue_name: nazwa nowej kolumny, która będzie zawierała wartości kolumn przekształconych na pary klucz-wartość. Domyślnie to ‘value’.\ncol_level: jeżeli kolumny są wielopoziomowe, to jest poziom, który będzie użyty do przekształcania kolumn na pary klucz-wartość.\n\n\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'A': ['foo', 'bar', 'baz'],\n    'B': ['one', 'one', 'two'],\n    'C': [2.0, 1.0, 3.0],\n    'D': [3.0, 2.0, 1.0]\n})\nprint(df)\nmelted_df = df.melt(id_vars=['A', 'B'], value_vars=['C', 'D'], var_name='My_Var', value_name='My_Val')\nprint(melted_df)\n\n     A    B    C    D\n0  foo  one  2.0  3.0\n1  bar  one  1.0  2.0\n2  baz  two  3.0  1.0\n     A    B My_Var  My_Val\n0  foo  one      C     2.0\n1  bar  one      C     1.0\n2  baz  two      C     3.0\n3  foo  one      D     3.0\n4  bar  one      D     2.0\n5  baz  two      D     1.0",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "pandas.html#tidy-data",
    "href": "pandas.html#tidy-data",
    "title": "5  Pandas",
    "section": "5.7 “Tidy data”",
    "text": "5.7 “Tidy data”\n\n\n\nImię\nWiek\nWzrost\nKolor oczu\n\n\n\n\nAdam\n26\n167\nBrązowe\n\n\nSylwia\n34\n164\nPiwne\n\n\nTomasz\n42\n183\nNiebieskie\n\n\n\n\njedna obserwacja (jednostka statystyczna) = jeden wiersz w tabeli/macierzy/ramce danych\nwartosci danej cechy znajduja sie w kolumnach\njeden typ/rodzaj obserwacji w jednej tabeli/macierzy/ramce danych",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "pandas.html#obsługa-brakujących-danych",
    "href": "pandas.html#obsługa-brakujących-danych",
    "title": "5  Pandas",
    "section": "5.8 Obsługa brakujących danych",
    "text": "5.8 Obsługa brakujących danych\n\nimport numpy as np\nimport pandas as pd\n\nstring_data = pd.Series(['aardvark', 'artichoke', np.nan, 'avocado'])\nprint(string_data)\nprint(string_data.isnull())\nprint(string_data.dropna())\n\n0     aardvark\n1    artichoke\n2          NaN\n3      avocado\ndtype: object\n0    False\n1    False\n2     True\n3    False\ndtype: bool\n0     aardvark\n1    artichoke\n3      avocado\ndtype: object\n\n\n\n\nfrom numpy import nan as NA\nimport pandas as pd\n\ndata = pd.DataFrame([[1., 6.5, 3.], [1., NA, NA], \n                     [NA, NA, NA], [NA, 6.5, 3.]])\ncleaned = data.dropna()\nprint(cleaned)\nprint(data.dropna(how='all'))\ndata[4] = NA\nprint(data.dropna(how='all', axis=1))\nprint(data)\nprint(data.fillna(0))\nprint(data.fillna({1: 0.5, 2: 0}))\n\n     0    1    2\n0  1.0  6.5  3.0\n     0    1    2\n0  1.0  6.5  3.0\n1  1.0  NaN  NaN\n3  NaN  6.5  3.0\n     0    1    2\n0  1.0  6.5  3.0\n1  1.0  NaN  NaN\n2  NaN  NaN  NaN\n3  NaN  6.5  3.0\n     0    1    2   4\n0  1.0  6.5  3.0 NaN\n1  1.0  NaN  NaN NaN\n2  NaN  NaN  NaN NaN\n3  NaN  6.5  3.0 NaN\n     0    1    2    4\n0  1.0  6.5  3.0  0.0\n1  1.0  0.0  0.0  0.0\n2  0.0  0.0  0.0  0.0\n3  0.0  6.5  3.0  0.0\n     0    1    2   4\n0  1.0  6.5  3.0 NaN\n1  1.0  0.5  0.0 NaN\n2  NaN  0.5  0.0 NaN\n3  NaN  6.5  3.0 NaN",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "pandas.html#usuwanie-duplikatów",
    "href": "pandas.html#usuwanie-duplikatów",
    "title": "5  Pandas",
    "section": "5.9 Usuwanie duplikatów",
    "text": "5.9 Usuwanie duplikatów\n\nimport pandas as pd\n\ndata = pd.DataFrame({'k1': ['one', 'two'] * 3 + ['two'],\n                     'k2': [1, 1, 2, 3, 3, 4, 4]})\nprint(data)\nprint(data.duplicated())\nprint(data.drop_duplicates())\n\n    k1  k2\n0  one   1\n1  two   1\n2  one   2\n3  two   3\n4  one   3\n5  two   4\n6  two   4\n0    False\n1    False\n2    False\n3    False\n4    False\n5    False\n6     True\ndtype: bool\n    k1  k2\n0  one   1\n1  two   1\n2  one   2\n3  two   3\n4  one   3\n5  two   4",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "pandas.html#zastępowanie-wartościami",
    "href": "pandas.html#zastępowanie-wartościami",
    "title": "5  Pandas",
    "section": "5.10 Zastępowanie wartościami",
    "text": "5.10 Zastępowanie wartościami\n\nimport pandas as pd\nimport numpy as np\n\ndata = pd.Series([1., -999., 2., -999., -1000., 3.])\nprint(data)\nprint(data.replace(-999, np.nan))\nprint(data.replace([-999, -1000], np.nan))\nprint(data.replace([-999, -1000], [np.nan, 0]))\nprint(data.replace({-999: np.nan, -1000: 0}))\n\n0       1.0\n1    -999.0\n2       2.0\n3    -999.0\n4   -1000.0\n5       3.0\ndtype: float64\n0       1.0\n1       NaN\n2       2.0\n3       NaN\n4   -1000.0\n5       3.0\ndtype: float64\n0    1.0\n1    NaN\n2    2.0\n3    NaN\n4    NaN\n5    3.0\ndtype: float64\n0    1.0\n1    NaN\n2    2.0\n3    NaN\n4    0.0\n5    3.0\ndtype: float64\n0    1.0\n1    NaN\n2    2.0\n3    NaN\n4    0.0\n5    3.0\ndtype: float64",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "pandas.html#dyskretyzacja-i-podział-na-koszyki",
    "href": "pandas.html#dyskretyzacja-i-podział-na-koszyki",
    "title": "5  Pandas",
    "section": "5.11 Dyskretyzacja i podział na koszyki",
    "text": "5.11 Dyskretyzacja i podział na koszyki\n\nimport pandas as pd\n\nages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]\nbins = [18, 25, 35, 60, 100]\ncats = pd.cut(ages, bins)\nprint(cats)\nprint(cats.codes)\nprint(cats.categories)\nprint(pd.Series(cats).value_counts())\n\n[(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], (60, 100], (35, 60], (35, 60], (25, 35]]\nLength: 12\nCategories (4, interval[int64, right]): [(18, 25] &lt; (25, 35] &lt; (35, 60] &lt; (60, 100]]\n[0 0 0 1 0 0 2 1 3 2 2 1]\nIntervalIndex([(18, 25], (25, 35], (35, 60], (60, 100]], dtype='interval[int64, right]')\n(18, 25]     5\n(25, 35]     3\n(35, 60]     3\n(60, 100]    1\nName: count, dtype: int64\n\n\n\n\nimport pandas as pd\n\nages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]\nbins = [18, 25, 35, 60, 100]\ncats2 = pd.cut(ages, [18, 26, 36, 61, 100], right=False)\nprint(cats2)\ngroup_names = ['Youth', 'YoungAdult',\n               'MiddleAged', 'Senior']\nprint(pd.cut(ages, bins, labels=group_names))\n\n[[18, 26), [18, 26), [18, 26), [26, 36), [18, 26), ..., [26, 36), [61, 100), [36, 61), [36, 61), [26, 36)]\nLength: 12\nCategories (4, interval[int64, left]): [[18, 26) &lt; [26, 36) &lt; [36, 61) &lt; [61, 100)]\n['Youth', 'Youth', 'Youth', 'YoungAdult', 'Youth', ..., 'YoungAdult', 'Senior', 'MiddleAged', 'MiddleAged', 'YoungAdult']\nLength: 12\nCategories (4, object): ['Youth' &lt; 'YoungAdult' &lt; 'MiddleAged' &lt; 'Senior']\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\ndata = np.random.rand(20)\nprint(pd.cut(data, 4, precision=2))\n\n[(0.6, 0.8], (0.8, 0.99], (0.8, 0.99], (0.8, 0.99], (0.21, 0.41], ..., (0.41, 0.6], (0.6, 0.8], (0.21, 0.41], (0.21, 0.41], (0.6, 0.8]]\nLength: 20\nCategories (4, interval[float64, right]): [(0.21, 0.41] &lt; (0.41, 0.6] &lt; (0.6, 0.8] &lt; (0.8, 0.99]]\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\ndata = np.random.randn(1000)\ncats = pd.qcut(data, 4)\nprint(cats)\nprint(pd.Series(cats).value_counts())\n\n[(0.0455, 0.701], (-2.936, -0.628], (0.0455, 0.701], (0.701, 2.96], (-2.936, -0.628], ..., (-2.936, -0.628], (0.701, 2.96], (-0.628, 0.0455], (0.701, 2.96], (-0.628, 0.0455]]\nLength: 1000\nCategories (4, interval[float64, right]): [(-2.936, -0.628] &lt; (-0.628, 0.0455] &lt; (0.0455, 0.701] &lt; (0.701, 2.96]]\n(-2.936, -0.628]    250\n(-0.628, 0.0455]    250\n(0.0455, 0.701]     250\n(0.701, 2.96]       250\nName: count, dtype: int64",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "pandas.html#wykrywanie-i-filtrowanie-elementów-odstających",
    "href": "pandas.html#wykrywanie-i-filtrowanie-elementów-odstających",
    "title": "5  Pandas",
    "section": "5.12 Wykrywanie i filtrowanie elementów odstających",
    "text": "5.12 Wykrywanie i filtrowanie elementów odstających\n\nimport pandas as pd\nimport numpy as np\n\ndata = pd.DataFrame(np.random.randn(1000, 4))\nprint(data.describe())\nprint(\"---\")\ncol = data[2]\nprint(col[np.abs(col) &gt; 3])\nprint(\"---\")\nprint(data[(np.abs(data) &gt; 3).any(axis=1)])\n\n                 0            1            2            3\ncount  1000.000000  1000.000000  1000.000000  1000.000000\nmean     -0.008157    -0.008605    -0.015022    -0.013411\nstd       1.020343     0.986787     1.010614     1.004372\nmin      -3.255828    -3.401794    -2.896372    -3.170670\n25%      -0.695911    -0.691773    -0.669510    -0.656232\n50%       0.018231     0.015628    -0.008745    -0.010759\n75%       0.673671     0.681947     0.621579     0.647639\nmax       3.030993     2.673720     3.922744     2.730629\n---\n64     3.244522\n246    3.922744\nName: 2, dtype: float64\n---\n            0         1         2         3\n64  -0.070290 -1.421039  3.244522 -0.667182\n186 -3.097677  0.314219  0.381369 -1.400277\n219 -3.255828  0.051760 -1.042812 -0.328216\n220  3.030993  0.575799  0.710388  1.337509\n233 -1.136049  0.269183  0.367068 -3.170670\n246 -1.477894  0.654825  3.922744 -0.601841\n501 -0.837768 -3.401794  0.262275 -0.216157\n655 -0.236919 -3.267062  0.245410 -0.665763",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "pandas.html#zmiana-typu-w-kolumnie",
    "href": "pandas.html#zmiana-typu-w-kolumnie",
    "title": "5  Pandas",
    "section": "5.13 Zmiana typu w kolumnie",
    "text": "5.13 Zmiana typu w kolumnie\n\nimport pandas as pd\n\n\ndata = {\n    'A': ['1', '2', '3', '4', '5', '6'],\n    'B': ['7.5', '8.5', '9.5', '10.5', '11.5', '12.5'],\n    'C': ['x', 'y', 'z', 'x', 'y', 'z']\n}\ndf = pd.DataFrame(data)\n\n# Wyświetlenie oryginalnej ramki danych\nprint(\"Oryginalna ramka danych:\")\nprint(df)\n\n# Zmiana typu danych kolumny 'A' na int\ndf['A'] = pd.Series(df['A'], dtype=int)\n\n# Zmiana typu danych kolumny 'B' na float\ndf['B'] = pd.Series(df['A'], dtype=float)\n\n# Wyświetlenie ramki danych po zmianie typów\nprint(\"\\nRamka danych po zmianie typów:\")\nprint(df)\n\nOryginalna ramka danych:\n   A     B  C\n0  1   7.5  x\n1  2   8.5  y\n2  3   9.5  z\n3  4  10.5  x\n4  5  11.5  y\n5  6  12.5  z\n\nRamka danych po zmianie typów:\n   A    B  C\n0  1  1.0  x\n1  2  2.0  y\n2  3  3.0  z\n3  4  4.0  x\n4  5  5.0  y\n5  6  6.0  z\n\n\n\nimport pandas as pd\n\n\ndata = {\n    'A': ['1', '2', '3', '4', '5', '6'],\n    'B': ['7.5', '8.5', '9.5', '10.5', '11.5', '12.5'],\n    'C': ['x', 'y', 'z', 'x', 'y', 'z']\n}\ndf = pd.DataFrame(data)\n\n# Wyświetlenie oryginalnej ramki danych\nprint(\"Oryginalna ramka danych:\")\nprint(df)\n\n# Zmiana typu danych kolumny 'A' na int\ndf['A'] = df['A'].astype(int)\n\n# Zmiana typu danych kolumny 'B' na float\ndf['B'] = df['B'].astype(float)\n\n# Wyświetlenie ramki danych po zmianie typów\nprint(\"\\nRamka danych po zmianie typów:\")\nprint(df)\n\nOryginalna ramka danych:\n   A     B  C\n0  1   7.5  x\n1  2   8.5  y\n2  3   9.5  z\n3  4  10.5  x\n4  5  11.5  y\n5  6  12.5  z\n\nRamka danych po zmianie typów:\n   A     B  C\n0  1   7.5  x\n1  2   8.5  y\n2  3   9.5  z\n3  4  10.5  x\n4  5  11.5  y\n5  6  12.5  z",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "pandas.html#zmiana-znaku-kategoriach",
    "href": "pandas.html#zmiana-znaku-kategoriach",
    "title": "5  Pandas",
    "section": "5.14 Zmiana znaku kategoriach",
    "text": "5.14 Zmiana znaku kategoriach\n\nimport pandas as pd\n\n# Tworzenie ramki danych\ndata = {\n    'A': ['abc', 'def', 'ghi', 'jkl', 'mno', 'pqr'],\n    'B': ['1.23', '4.56', '7.89', '0.12', '3.45', '6.78'],\n    'C': ['xyz', 'uvw', 'rst', 'opq', 'lmn', 'ijk']\n}\ndf = pd.DataFrame(data)\n\n# Wyświetlenie oryginalnej ramki danych\nprint(\"Oryginalna ramka danych:\")\nprint(df)\n\n# Zmiana małych liter na duże w kolumnie 'A'\ndf['A'] = df['A'].str.upper()\n\n# Zastąpienie kropki przecinkiem w kolumnie 'B'\ndf['B'] = df['B'].str.replace('.', ',')\n\n# Wyświetlenie ramki danych po modyfikacji\nprint(\"\\nRamka danych po modyfikacji:\")\nprint(df)\n\nOryginalna ramka danych:\n     A     B    C\n0  abc  1.23  xyz\n1  def  4.56  uvw\n2  ghi  7.89  rst\n3  jkl  0.12  opq\n4  mno  3.45  lmn\n5  pqr  6.78  ijk\n\nRamka danych po modyfikacji:\n     A     B    C\n0  ABC  1,23  xyz\n1  DEF  4,56  uvw\n2  GHI  7,89  rst\n3  JKL  0,12  opq\n4  MNO  3,45  lmn\n5  PQR  6,78  ijk\n\n\nBibliografia:\n\nDokumentacja biblioteki, https://pandas.pydata.org/, dostęp online 5.03.2021.\nHannah Stepanek, Thinking in Pandas, How to Use the Python Data Analysis Library the Right Way, Apress, 2020.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  }
]